{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4027d83f",
   "metadata": {},
   "source": [
    "## Running ActiveMatcher on a Single Machine (the Basic Mode)\n",
    "\n",
    "Here we will walk through an example of running ActiveMatcher on a single machine. In particular, we show how to create a Python program step by step, then execute it. We assume you have installed ActiveMatcher on a single machine, using [this guide](https://github.com/anhaidgroup/active_matcher/blob/main/doc/installation-guides/install-single-machine.md).\n",
    "\n",
    "ActiveMatcher can be run in either the basic mode or the advanced mode. This document describes the basic mode. We motivate the advanced mode and describe it [here](https://github.com/anhaidgroup/active_matcher/blob/main/doc/usage-guides/usage-guide-advanced-mode.md). If you want to learn the advanced mode, we recommend learning the basic mode described in this document first. \n",
    "\n",
    "### Step 1: Download the Datasets\n",
    "\n",
    "First we download the datasets from GitHub. Navigate to the [dblp_acm folder](https://github.com/anhaidgroup/active_matcher/tree/main/examples/data/dblp_acm) then click 'cand.parquet' and click the download icon at the top. Repeat this for 'gold.parquet', 'table_a.parquet', and 'table_b.parquet'. Now move all these into a local folder called 'dblp_acm'. To explain these files: \n",
    "* The files 'table_a.parquet' and 'table_b.parquet' contain the tuples of Table A and Table B, respectively. Our goal is to match A and B, that is, find matches between them. \n",
    "* We assume blocking (e.g., using Sparkly or Delex) has been done. The file 'cand.parquet' contains candidate tuple pairs that are output by the blocker. Each tuple pair is of the form (x,y) where x is a tuple in A and y is a tuple in B. The goal of ActiveMatcher is to predict for each such tuple pair whether it is a match or non-match.\n",
    "* The file 'gold.parquet' contains the gold matches, that is, the IDs of all tuple pairs that are matches between Tables A and B. This file is used here only to simulate a user's labeling a set of tuple pairs for training a matcher, and to compute the accuracy of the matching step. Obviously when you apply ActiveMatcher \"for real\", you will not have access to the gold matches. \n",
    "\n",
    "### Step 2: Download the Python Notebook\n",
    "\n",
    "Download this Python Notebook and move it into the 'dblp_acm' folder you created above.\n",
    "\n",
    "### Step 3: Import the Dependencies\n",
    "\n",
    "Now we add the following code to the Python file to import all of the necessary packages that we will use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f25bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "import shutil\n",
    "from sklearn.metrics import f1_scoremodel\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from active_matcher.active_learning import EntropyActiveLearner\n",
    "from active_matcher.fv_generator import FVGenerator\n",
    "from active_matcher.feature_selector import FeatureSelector\n",
    "from active_matcher.ml_model import  SKLearnModel, SparkMLModel\n",
    "from active_matcher.labeler import  GoldLabeler\n",
    "from active_matcher.algorithms import select_seeds\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "from pathlib import Path\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f2e50",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Initialize Spark\n",
    "\n",
    "Next we initialize Spark, which runs in the local mode (that is, on your local machine) in this example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark =  SparkSession.builder\\\n",
    "                        .master('local[*]')\\\n",
    "                        .config('spark.sql.execution.arrow.pyspark.enabled',  'true')\\\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd621e",
   "metadata": {},
   "source": [
    "\n",
    "### Step 4: Reading the Data\n",
    "\n",
    "Once we have the SparkSession initialized, we read in the tables along with our candidate set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./')\n",
    "A = spark.read.parquet(str(data_dir / 'table_a.parquet'))\n",
    "B = spark.read.parquet(str(data_dir / 'table_b.parquet'))\n",
    "cand = spark.read.parquet(str(data_dir / 'cand.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42378c",
   "metadata": {},
   "source": [
    "\n",
    "Here the provided datasets, table_a and table_b, have the same schema. ***ActiveMatcher requires that the datasets (that is, tables) being matched have the same schema. This schema must also contain an ID column.*** Note that each tuple (that is, record) must have a value for this ID column and all values (across the tuples) must be different. Here the ID columns for both table_a and table_b are named '_id'.\n",
    "\n",
    "The candidate set file 'cand.parquet' is a set of rolled up pairs, where cand['id2'] refers to the B['_id'] of the records in Table B and the ids in cand['id1_list'] refer to the records in Table A with ids A['_id']. This is an efficient way to store and manipulate a large number of candidate tuple pairs. \n",
    "\n",
    "### Step 6: Specifying a Labeler\n",
    "\n",
    "ActiveMatcher uses a labeler to label a candidate tuple pair as match or non-match. It does this in the step to create a set of seeds for the active learning process and in the step of active learning itself (as we describe soon). \n",
    "\n",
    "Currently ActiveMatcher provides a command-line interface (CLI) labeler, a Web-based labeler, and a gold labeler. In what follows we discuss using these labelers. \n",
    "\n",
    "#### Using the Command-Line Interface (CLI) Labeler\n",
    "\n",
    "We have provided a labeler that operates within the command-line interface (CLI). To specify this labeler, you should put the following code into the Python file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_matcher.labeler import CLILabeler\n",
    "\n",
    "labeler = CLILabeler(a_df=A, b_df=B, id_col:'_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c64e11",
   "metadata": {},
   "source": [
    "Here '_id' is the name of the ID columns for Tables A and B. This labeler will display a pair of tuples (x,y) to the CLI, side by side, then ask you to specify if x and y match, or do not match, or if you are unsure. It then displays the next pair of tuples, and so on. \n",
    "\n",
    "#### Using the Web Labeler\n",
    "\n",
    "We have provided a Web-based labeler that the user can use to label tuple pairs when running ActiveMatcher. Specifically, when the Spark process underlying ActiveMatcher needs to label tuple pairs, it sends these pairs to a Flask-based Web server, which in turn sends these pairs to a Streamlit GUI, where the user can label. Once done, the labeled pairs are sent back to the Flask Web server, which in turn sends them back to the Spark process. \n",
    "\n",
    "The Flask-based Web server and the Streamlit GUI are hosted on the user's local machine. \n",
    "\n",
    "To use this Web labeler, put the following code into the Python file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_matcher.labeler import WebUILabeler\n",
    "\n",
    "labeler = WebUILabeler(a_df=A, b_df=B, id_col:'_id', flask_port=5005, streamlit_port=8501, flask_host='127.0.0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a27b8",
   "metadata": {},
   "source": [
    "To explain the above paramaters: \n",
    "* Here '_id' is the name of the ID columns for Tables A and B.\n",
    "* The 'flask_port' will be the port number for the Flask server to run on. The 'streamlit_port' will be the port number for the Streamlit app to be run on.\n",
    "* Unless you have other processes running on port 5005 and/or 8501, there should be no need to change the default arguments for 'flask_port' or 'streamlit_port'. It is important that the 'flask_port' and 'streamlit_port' are two distinct values. You may not set them both to the same value.\n",
    "* Next, 'flask_host' is the IP where the Flask server should be running. By using the default value of '127.0.0.1', we are running the Flask server locally. This means that only processes on the same machine can call the Flask endpoints (which is fine for this example).\n",
    "\n",
    "The Streamlit UI will be run on 0.0.0.0, and you will be able to access it from your machine.\n",
    "\n",
    "On your local machine you can open 127.0.0.1:{streamlit_port} in the browser of your choice to see the Web UI.\n",
    "\n",
    "The Web UI will display a pair of tuples (x,y), side by side, then ask you to specify if x and y match, or do not match, or if you are unsure. It then displays the next pair of tuples, and so on. \n",
    "\n",
    "#### Using the Gold Labeler\n",
    "\n",
    "*In this example, since we do have access to gold, that is, tuple pairs that are matches between Tables A and B, we will use the gold labeler,* by adding the following code to the Python file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.read_parquet(data_dir / 'gold.parquet')\n",
    "gold = set(zip(gold_df.id1, gold_df.id2))\n",
    "labeler = GoldLabeler(gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece44d8a",
   "metadata": {},
   "source": [
    "Here, if ActiveMatcher wants to know if a pair of tuples (x,y) is a match or non-match, it simply consults 'gold'. Thus, this is a \"simulated\" active learning process which is completely automatic. It is not a \"real\" active learning process (like with the CLI Labeler), because it does not require a human user to be in the loop (to label the tuple pairs). \n",
    "\n",
    "Such simulated active learning using gold is very useful for code development, debugging, and computing the accuracy of the matching process. *For the rest of this example, we will use this gold labeler.*\n",
    "\n",
    "#### Using Other Labelers\n",
    "\n",
    "Currently we do not provide more labelers. But you can extend the labeling code in ActiveMatcher to create more powerful labelers. You can do this by subclassing the Labeler class (see the CLI Labeler for an example of subclassing). \n",
    " \n",
    "### Step 7: Creating a Machine Learning Model to Serve as the Matcher\n",
    "\n",
    "Next we specify a machine learning (ML) classification model to serve as the matcher. Here we will use XGBClassifier, which exposes an SKLearn model interface. In general, you can select any classification model that you believe will fit your data well and exposes an SKLearn or SparkML model interface. \n",
    " \n",
    "SKLearn model options are described [here](https://scikit-learn.org/stable/supervised_learning.html), and SparkML model options are described [here](https://spark.apache.org/docs/latest/ml-classification-regression.html). Note that even though XGBClassifier exposes an SKLearn model interface, it is not included in the SKLearn package and so is not described there. See instead its documentation [here](https://xgboost.readthedocs.io/en/stable/index.html). \n",
    "\n",
    "To continue with our example, the following code specifies the XGBClassifier model: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e3365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SKLearnModel(XGBClassifier, eval_metric='logloss', objective='binary:logistic', max_depth=6, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b1a75",
   "metadata": {},
   "source": [
    "Note that we pass the type of model (XGBClassifier), not a model instance. Additionally, we pass model-specific keyword args as we would when constructing the model normally. In this case we passed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric='logloss', objective='binary:logistic', max_depth=6, seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87bea7",
   "metadata": {},
   "source": [
    "#### Avoid Models with Slow Training and/or Inference\n",
    "Each iteration in the active learning process requires training a new model and then applying that model to each feature vector we are doing active learning on. So you should avoid using a model where training and/or inference (that is, model application) are slow, otherwise the active learning process will be slow. Use such a model only if you think the benefits (for example, higher accuracy) will outweigh the long runtime. \n",
    "\n",
    "#### Avoid Threading for SKLearn Models\n",
    "You do not need to take any action here. This part is only for your information. Many ML models use multiple threads for inference. However, SKLearn models appear to have a problem using multiple threads for inference. So this should be disabled. \n",
    "\n",
    "Fortunately, SKLearn provides an easy way to disable threading using threadpoolctl. In the ActiveMatcher code, SKLearnModel automatically disables threading for inference using threadpoolctl. So SKLearn models do not require any modification and can be passed to SKLearnModel unchanged. If you want to read more about this issue, see [this document](https://scikit-learn.org/stable/computing/parallelism.html#oversubscription-spawning-too-many-threads).\n",
    "\n",
    "The above threading issue is specific to SKLearn models. It does not affect SparkML models.\n",
    "\n",
    "### Step 8: Creating Features for the ML Model\n",
    "\n",
    "We now create a set of features. In the next step we will use these features to convert each pair of tuples (x,y) in the candidate set into a feature vector. We use the following code to create the features: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FeatureSelector(extra_features=False)\n",
    "features = selector.select_features(A.drop('_id'), B.drop('_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30642f6",
   "metadata": {},
   "source": [
    "The above code snippet will create features that compute similarity scores between the attributes of Table A and Table B. For example, a feature may compute the Jaccard score between A.name and B.name, after the names have been tokenized into sets of 3-grams. Another feature may compute the TF/IDF score between A.address and B.address, and so on. *ActiveMatcher uses heuristics to examine the attributes of Tables A and B and automatically generate these features.*\n",
    "\n",
    "Note that in the above code snippet, we pass 'extra_features=False' to FeatureSelector. If we set 'extra_features=True', ActiveMatcher will generate even more features. This may improve the ML model's accuracy, but will increase the time to generate the feature vectors and to perform active learning. \n",
    "\n",
    "### Step 9: Creating the Feature Vectors\n",
    "\n",
    "Now we use the features created in the previous step to convert all tuple pairs in the candidate set into feature vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_gen = FVGenerator(features) \n",
    "fv_gen.build(A, B) \n",
    "fvs = fv_gen.generate_fvs(cand) \n",
    "fvs = model.prep_fvs(fvs, 'features') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d399413",
   "metadata": {},
   "source": [
    "In the above code snippet\n",
    "* Line 1 creates an FVGenerator object with the features previously created.\n",
    "* Line 2 creates a binary representation of the DataFrame 'cand' and stores it on disk. This is a memory optimization to avoid the large dataframes being kept in memory.\n",
    "* Line 3 creates a feature vector for each tuple pair in the cand set.\n",
    "* Line 4 ensures that fvs is the correct datatype (vector or array), fills in NaN values, and saves the feature vectors (fvs) in a column called 'features'.\n",
    "\n",
    "### Step 10: Scoring the Feature Vectors\n",
    "\n",
    "Next we compute a score for each feature vector, such that the higher the score, the more likely that it is a match. Later we will use these scores to select a set of seeds for active learning (and optionally to obtain a sample of the candidate set for active learning in the \n",
    "advanced mode). \n",
    "\n",
    "Here we compute the score of each feature vector to be the sum of all components of that vector. This is based on the heuristic that each component of a vector is a similarity score (such as Jaccard, cosine), so the higher the sum of these similarity scores, the more likely that the feature vector is a match (that is, the tuple pair corresponding to this vector is a match): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs = fvs.withColumn('score', F.aggregate('features', F.lit(0.0), lambda acc, x : acc + F.when(x.isNotNull() & ~F.isnan(x), x).otherwise(0.0) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c088077",
   "metadata": {},
   "source": [
    "\n",
    "### Step 11: Selecting Seeds\n",
    "\n",
    "Next we select a small set of tuple pairs that we will label. This set of tuple pairs will serve as \"seeds\" to start the active learning process. Specifically, we will use these seeds to train an initial matcher. Then we use the matcher to look for unlabeled \"informative\" tuple pairs, then we ask the user to label those pairs and retrain the matcher, and so on. \n",
    "\n",
    "We select a set of 50 seeds as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = select_seeds(fvs, 50, labeler, 'score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff0400",
   "metadata": {},
   "source": [
    "Here the scores that we have computed in the previous step are stored in the column 'score'. We select 25 feature vectors that have the highest scores (so they are most likely to be matches) and 25 feature vectors that have the lowest scores (so they are likely to be non-matches). \n",
    "\n",
    "### Step 12: Using Active Learning to Train the Matcher\n",
    "\n",
    "We now use active learning to train the matcher by adding the following code to the Python file:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaefd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner = EntropyActiveLearner(model, labeler, batch_size=10, max_iter=50)\n",
    "trained_model = active_learner.train(fvs, seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df729f3",
   "metadata": {},
   "source": [
    "In the above code \n",
    "* We ask the user to label the selected seeds (as matches or non-matches), using the labeler 'labeler'.\n",
    "* Then we use the labeled seeds to train the matcher specified in 'model' (which is a ML classifier in this case).\n",
    "* Then we perform up to 'max_iter=50' iterations. In each iteration\n",
    "  + we apply the trained matcher to all feature vectors (in the candidate set) to predict them as matches/non-matches,\n",
    "  + use these predictions to select the top 'batch_size=10' most informative tuple pairs,\n",
    "  + ask the user to label these selected tuple pairs as matches/non-matches,\n",
    "  + then re-train the matcher using *all* tuple pairs that have been labeled so far.\n",
    "\n",
    "The above training process stops when we have finished 'max_iter=50' iterations, or when we have run out of tuple pairs to select. In any case, we return the matcher that has been trained with all tuple pairs that have been labeled so far. \n",
    "   \n",
    "### Step 13: Applying the Trained Matcher\n",
    "\n",
    "We can now apply the trained matcher to the feature vectors in the candidate set, which is stored in 'fvs'. This produces the binary predictions in column fvs['prediction'] and the confidence score of the prediction in column fvs['condifidence']. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6edd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvs = trained_model.predict(fvs, 'features', 'prediction')\n",
    "fvs = trained_model.prediction_conf(fvs, 'features', 'confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4a5bc",
   "metadata": {},
   "source": [
    "The binary prediction is 1.0 or 0.0. 1.0 implies that the model predicts two records are a match, and 0.0 implies not a match. Then, the confidence score is in the range of \\[0.50, 1.0\\]. The confidence score is the model's estimation of the probability that the 'prediction' is correct. For example if 'prediction' is 1.0 and 'confidence' is .85, then the model is 85% confident that two records are a match. On the other hand, if 'prediction' is 0.0 and 'confidence' is .85, then the model is 85% confident that two records do not match.\n",
    "\n",
    "Finally, we can compute precision, recall, and f1 of the predictions made by the matcher:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fvs.toPandas()\n",
    "\n",
    "predicted_matches = set(res.loc[res['prediction'].eq(1.0)][['id1', 'id2']].itertuples(name=None, index=False))\n",
    "\n",
    "true_positives = len(gold & predicted_matches)\n",
    "precision = true_positives / len(predicted_matches)\n",
    "recall = true_positives / len(gold)\n",
    "f1 = (precision * recall * 2) / (precision + recall)\n",
    "\n",
    "print(\n",
    "f'''\n",
    "{true_positives=}\n",
    "{precision=}\n",
    "{recall=}\n",
    "{f1=}\n",
    "'''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
